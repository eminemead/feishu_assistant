# NVIDIA Developer Platform (Primary - Free)
# Uses minimaxai/minimax-m2.1 via NVIDIA's API directly
# Get your key from: https://build.nvidia.com/
NVIDIA_URL=https://integrate.api.nvidia.com/v1
NVIDIA_API_TOKEN=your_nvidia_api_token_here

# OpenRouter API Key (Fallback - used when NVIDIA_API_TOKEN not set)
# Get your key from: https://openrouter.ai/
# Set USE_OPENROUTER=true to force OpenRouter instead of NVIDIA
OPENROUTER_API_KEY=your_openrouter_api_key_here
# USE_OPENROUTER=true

# OpenAI API Key (Required for semantic recall embeddings)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Internal Model API (Optional - used as fallback and for embeddings)
# Example: NIO Model Gateway (https://modelgateway.nioint.com/publicService)
# When configured, used for:
#   - Fallback LLM when OpenRouter fails
#   - Embedding model for semantic recall (reduces costs)
# INTERNAL_MODEL_API_ENDPOINT=https://modelgateway.nioint.com/publicService
# INTERNAL_MODEL_API_KEY=your_bearer_token
# INTERNAL_MODEL_NAME=Qwen3-Next-80B

# AI Model Tier Selection (Optional)
# Options:
#   - "primary": kwaipilot/kat-coder-pro:free (free, may have rate limits)
#   - "fallback": google/gemini-2.5-flash-lite (reliable, no rate limits)
# Default: primary (tries free model, logs warnings if rate limited)
# AI_MODEL_TIER=primary

# Feishu Configuration (Required)
FEISHU_APP_ID=your_feishu_app_id
FEISHU_APP_SECRET=your_feishu_app_secret
FEISHU_SUBSCRIPTION_MODE=true

# Optional: Feishu Webhook (only if using webhook mode instead of subscription)
# FEISHU_ENCRYPT_KEY=your_encrypt_key
# FEISHU_VERIFICATION_TOKEN=your_verification_token

# Supabase Configuration (Optional - uses in-memory storage if not set)
# SUPABASE_URL=your_supabase_url
# SUPABASE_SERVICE_KEY=your_supabase_service_key (required for document tracking via webhooks)
# SUPABASE_ANON_KEY=your_supabase_anon_key
# SUPABASE_JWT_SECRET=your_jwt_secret

# Web Search (Optional)
# EXA_API_KEY=your_exa_api_key

# Server Configuration (Optional)
# PORT=3000
NODE_ENV=development
ENABLE_DEVTOOLS=true

# Arize Phoenix Observability (Optional - for AI tracing)
# Phoenix is an open-source observability platform for LLM applications
# Deploy with: docker run -p 6006:6006 arizephoenix/phoenix
PHOENIX_ENDPOINT=http://localhost:6006/v1/traces
# PHOENIX_API_KEY=your-api-key  # Optional for local instances
PHOENIX_PROJECT_NAME=feishu-assistant

# Dagster Integration (Optional - for pipeline notifications)
# DAGSTER_WEBHOOK_SECRET=your_shared_secret  # For validating webhook requests from Dagster
# DAGSTER_NOTIFY_CHAT_ID=oc_xxxxx  # Default Feishu chat ID for pipeline notifications

# Visualization Configuration (Optional)
# Default render mode for charts: auto | ascii | datawrapper | mermaid | vega-lite
# - auto: Uses datawrapper if available, otherwise ascii (recommended)
# - ascii: Instant emoji/unicode charts, works everywhere
# - datawrapper: Professional PNG charts (requires DATAWRAPPER_API_KEY)
# VISUALIZATION_DEFAULT_MODE=auto

# Datawrapper API (Optional - for professional chart generation)
# Get your key from: https://app.datawrapper.de/account/api-tokens
# DATAWRAPPER_API_KEY=your_datawrapper_api_key

# Logging Configuration (Optional)
# LOG_LEVEL=debug  # Options: debug, info, warn, error (default: debug in dev, info in prod)
